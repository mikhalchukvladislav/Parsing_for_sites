# Parsing_for_sites
 Get all page links

Алгоритм запуска проекта:
- запустить три терминала одновременно:
    - в первом терминале выполнить команду: python manage.py runserver;
    - во втором запустить Redis;
    - в третьем выполнить команду для запуска Celery: celery -A Parsing worker -l INFO;
- при переходе в браузер отображена таблица со всеми результатами введеных запросов ранее;
- чтобы спарсить сайт, необходимо нажать на вкладку "Url Parsing":
    - на странице парсинга ввести в форму ссылку на сайт, который необходимо спарсить, и нажать кнопку "Scrab the link";
    - результат запроса будет выведен на отдельную страницу, соответствующую id, введеной в форме ссылки, из базы данных;
    - результат запроса содержит "найденный url", "domain", "create_date", "update_date", "country", "isDead", "A", "NS", "CNAME", "MX", "TXT" для каждой ссылки на странице, которую указали в форме запроса;
    - чтобы вернуться на главную странцицу со всеми результатами, необходимо нажать на вкладку "Url Table";
- все результаты запросов и введеные ссылки в форме хранятся в базе данных.
